{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPFashion_Bihi_ahllamara.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I0Ml97kUDs-",
        "colab_type": "code",
        "outputId": "d5583888-f210-4103-f9c1-fdbfb22d684a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzeF2_WMUHZh",
        "colab_type": "code",
        "outputId": "d7c4dedc-212e-45f9-d7a3-1ec07f104399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR3_bebOUrzp",
        "colab_type": "code",
        "outputId": "c4711073-e018-4cac-df4e-b1cbfeea9b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd content/drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrTBEBdUUxTy",
        "colab_type": "code",
        "outputId": "7f430c7d-235e-4650-c3e6-d159de57cca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ODiiaMUHle",
        "colab_type": "code",
        "outputId": "e947bef6-22dd-4d9c-b6c3-1396d465593b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd TP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My3B0NqXRS1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importation des librairies utiles\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "#tf.set_image_dim_ordering('th')\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn import linear_model\n",
        "from sklearn import neural_network\n",
        "\n",
        "from sklearn import neighbors\n",
        "#from sklearn import cross_validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from nolearn.dbn import DBN\n",
        "import timeit\n",
        "import tensorflow_probability as tfp\n",
        "import time\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M66D0KkERrHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fonction pour preparer les donnees \n",
        "def get_and_prepare_data():\n",
        "    # chargement:\n",
        "    with open('dataset_TP3.pkl','rb') as f: \n",
        "      images, labels = pickle.load(f)\n",
        "\n",
        "\n",
        "    #construction des donnees tests et donnees d'apprentissage\n",
        "\n",
        "    T= [i for i in range(0,60000)]\n",
        "    I= [random.randint(0,59999) for i in range(48000)]   \n",
        "    J= list(set(T).symmetric_difference(set(I)))\n",
        "    train_image, train_labels= images[I], labels[I]\n",
        "    test_image, test_labels= images[J], labels[J] \n",
        "    train_image = train_image.reshape(train_image.shape[0],28, 28,1).astype('float32')\n",
        "    test_image = test_image.reshape(test_image.shape[0],28,28,1).astype('float32')\n",
        "    input_shape = (28, 28,1)\n",
        "    \n",
        "    #pre-traitement des donnees --> normalisation \n",
        "    train_image = train_image/ 255\n",
        "    test_image = test_image / 255\n",
        "      # one hot encode outputs\n",
        "    train_labels = np_utils.to_categorical(train_labels)\n",
        "    test_labels = np_utils.to_categorical(test_labels)\n",
        "    num_classes = test_labels.shape[1]\n",
        "    return (train_image, train_labels), (test_image, test_labels), num_classes \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjlPwjH3hOYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fonction pour preparer les donnees \n",
        "def get_and_prepare_data2():\n",
        "    # chargement:\n",
        "    with open('dataset_TP3.pkl','rb') as f: \n",
        "      images, labels = pickle.load(f)\n",
        "\n",
        "\n",
        "    #construction des donnees tests et donnees d'apprentissage\n",
        "\n",
        "    T= [i for i in range(0,60000)]\n",
        "    I= [random.randint(0,59999) for i in range(48000)]   \n",
        "    J= list(set(T).symmetric_difference(set(I)))\n",
        "    train_image, train_labels= images[I], labels[I]\n",
        "    test_image, test_labels= images[J], labels[J] \n",
        "    train_image = train_image.reshape(train_image.shape[0],28, 28).astype('float32')\n",
        "    test_image = test_image.reshape(test_image.shape[0],28,28).astype('float32')\n",
        "    input_shape = (28, 28,1)\n",
        "    \n",
        "    #pre-traitement des donnees --> normalisation \n",
        "    train_image = train_image/ 255\n",
        "    test_image = test_image / 255\n",
        " \n",
        "    return (train_image, train_labels), (test_image, test_labels)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90DdEeORwi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(train_image, train_labels), (test_image, test_labels) = get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agt18AsBRz9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image = train_image.reshape(train_image.shape[0],28, 28).astype('float32')\n",
        "test_image = test_image.reshape(test_image.shape[0],28,28).astype('float32')\n",
        "\n",
        "#1 er modele: ANN (reseau de neurones artificiel)\n",
        "modelANN = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28,28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "modelANN.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "modelANN.fit(train_image, train_labels, epochs=30, batch_size=32)\n",
        "modelANN.evaluate(test_image, test_labels)\n",
        " #score\n",
        "score1 = modelANN.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score1[0])\n",
        "print('Test accuracy:', score1[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COqRa7RwdcSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0AR2NVUR2rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2 eme modele: CNN (reseau de neurones convolutif)\n",
        "\n",
        "#CNN1 small modele                                      #on a deux couches de convolution \n",
        "  # create model\n",
        "  modelCNN1 = Sequential()\n",
        "  modelCNN1.add(Conv2D(64, (3, 3), input_shape=(28,28,1), activation='relu'))\n",
        "  modelCNN1.add(Conv2D(32, (3, 3),input_shape=(28,28,1), activation='relu'))\n",
        "  modelCNN1.add(Flatten())\n",
        "  modelCNN1.add(Dense(num_classes, activation='softmax'))\n",
        "  # Compile model\n",
        "  modelCNN1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  #fit du model\n",
        "  modelCNN1.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "  #score\n",
        "  score2 = modelCNN1.evaluate(test_image, test_labels, verbose=1)\n",
        "  print('Test loss:', score2[0])\n",
        "  print('Test accuracy:', score2[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_sfYlF5dhgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxEXNssASNip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN 3   #on joue aussi sur les couches de filtres (convolutional layers)   #on a 3 couches \n",
        "# create model\n",
        "modelCNN3 = Sequential()\n",
        "modelCNN3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28,1)))\n",
        "modelCNN3.add(MaxPooling2D((2, 2)))\n",
        "modelCNN3.add(Dropout(0.25))\n",
        "\n",
        "modelCNN3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "modelCNN3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN3.add(Dropout(0.25))\n",
        "\n",
        "modelCNN3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "modelCNN3.add(Dropout(0.4))\n",
        "\n",
        "modelCNN3.add(Flatten())\n",
        "\n",
        "modelCNN3.add(Dense(128, activation='relu'))\n",
        "modelCNN3.add(Dropout(0.3))\n",
        "modelCNN3.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN3.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN3.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=20, batch_size=200)\n",
        "#score\n",
        "score4 = modelCNN3.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score4[0])\n",
        "print('Test accuracy:', score4[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXKQcZ2be3ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgISctpVSUHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN 4   #on joue aussi sur les couches de filtres (convolutional layers)  #on a 4 couches \n",
        "# create model\n",
        "modelCNN4 = Sequential()\n",
        "modelCNN4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28,1)))\n",
        "modelCNN4.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "\n",
        "modelCNN4.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "modelCNN4.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN4.add(Dropout(0.25))\n",
        "\n",
        "modelCNN4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "modelCNN4.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN4.add(Dropout(0.25))\n",
        "\n",
        "modelCNN4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "modelCNN4.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN4.add(Dropout(0.25))\n",
        "\n",
        "modelCNN4.add(Flatten())\n",
        "\n",
        "modelCNN4.add(Dense(512, activation='relu'))\n",
        "modelCNN4.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN4.add(Dropout(0.5))\n",
        "\n",
        "modelCNN4.add(Dense(128, activation='relu'))\n",
        "modelCNN4.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN4.add(Dropout(0.5))\n",
        "\n",
        "modelCNN4.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN4.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN4.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score5 = modelCNN4.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score5[0])\n",
        "print('Test accuracy:', score5[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tMuTC-We6SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W2na498SZxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN 5     #on va jouer sur la fonction loss #on utilise KL  #on a une seule couche \n",
        "# create model\n",
        "modelCNN5 = Sequential()\n",
        "modelCNN5.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28,1)))\n",
        "modelCNN5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN5.add(Dropout(0.2))\n",
        "modelCNN5.add(Flatten())\n",
        "modelCNN5.add(Dense(128, activation='relu'))\n",
        "modelCNN5.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN5.compile(loss='kullback_leibler_divergence',\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN5.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score6 = modelCNN5.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score6[0])\n",
        "print('Test accuracy:', score6[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSOVXAk5e74Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFW8tAZ0Sfph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN 6     #on va jouer sur la fonction d'activation (on prend sigmoid a la place de relu)\n",
        "# create model\n",
        "modelCNN6 = Sequential()\n",
        "modelCNN6.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid', input_shape=(28, 28,1)))\n",
        "modelCNN6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN6.add(Dropout(0.2))\n",
        "modelCNN6.add(Flatten())\n",
        "modelCNN6.add(Dense(128, activation='sigmoid'))\n",
        "modelCNN6.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN6.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN6.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score7 = modelCNN6.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score7[0])\n",
        "print('Test accuracy:', score7[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwjbNAOVe9OB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzSt7wKXSjap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN 7     #on va jouer sur la fonction d'activation (on prend tanh a la place de relu)\n",
        "# create model\n",
        "modelCNN7 = Sequential()\n",
        "modelCNN7.add(Conv2D(32, kernel_size=(3, 3), activation='tanh', input_shape=(28, 28,1)))\n",
        "modelCNN7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN7.add(Dropout(0.2))\n",
        "modelCNN7.add(Flatten())\n",
        "modelCNN7.add(Dense(128, activation='tanh'))\n",
        "modelCNN7.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN7.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN7.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score8 = modelCNN7.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score8[0])\n",
        "print('Test accuracy:', score8[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akkkti9-e-pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E20pnmY2Srvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN8     #on va jouer sur le pooling  (sans le max pooling) #on a une seule couche \n",
        "# create model\n",
        "modelCNN8 = Sequential()\n",
        "modelCNN8.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28,1)))\n",
        "modelCNN8.add(Dropout(0.2))\n",
        "modelCNN8.add(Flatten())\n",
        "modelCNN8.add(Dense(128, activation='relu'))\n",
        "modelCNN8.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN8.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN8.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score9 = modelCNN8.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score9[0])\n",
        "print('Test accuracy:', score9[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGTFQn74e_5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SkFdPWYYUsB",
        "colab_type": "code",
        "outputId": "32eee414-b8f0-414a-918f-a4cd45b9ecc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#CNN9     #on va jouer sur la taille des filtres (5,5) et (3,3)  #on a deux couches\n",
        "# create model\n",
        "modelCNN9 = Sequential()\n",
        "modelCNN9.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), padding='same',activation='relu'))\n",
        "modelCNN9.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "modelCNN9.add(Conv2D(15, (3, 3), padding='same', activation='relu'))\n",
        "modelCNN9.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "modelCNN9.add(Dropout(0.2))\n",
        "modelCNN9.add(Flatten())\n",
        "modelCNN9.add(Dense(128, activation='relu'))\n",
        "modelCNN9.add(Dense(50, activation='relu'))\n",
        "modelCNN9.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN9.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score10 = modelCNN9.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score10[0])\n",
        "print('Test accuracy:', score10[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 26961 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: 0.6904 - acc: 0.7437 - val_loss: 0.4510 - val_acc: 0.8416\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 53s 1ms/sample - loss: 0.4285 - acc: 0.8457 - val_loss: 0.3864 - val_acc: 0.8619\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 53s 1ms/sample - loss: 0.3691 - acc: 0.8678 - val_loss: 0.3470 - val_acc: 0.8759\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.3351 - acc: 0.8785 - val_loss: 0.3197 - val_acc: 0.8840\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 53s 1ms/sample - loss: 0.3039 - acc: 0.8876 - val_loss: 0.3014 - val_acc: 0.8911\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.2844 - acc: 0.8962 - val_loss: 0.2908 - val_acc: 0.8957\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.2662 - acc: 0.9029 - val_loss: 0.2736 - val_acc: 0.9010\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 53s 1ms/sample - loss: 0.2543 - acc: 0.9060 - val_loss: 0.2651 - val_acc: 0.9019\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.2415 - acc: 0.9104 - val_loss: 0.2696 - val_acc: 0.9024\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.2258 - acc: 0.9157 - val_loss: 0.2611 - val_acc: 0.9050\n",
            "26961/26961 [==============================] - 11s 401us/sample - loss: 0.2611 - acc: 0.9050\n",
            "Test loss: 0.2610731114315963\n",
            "Test accuracy: 0.90501094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Su689-fBUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW2rDVn5YZDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN10     #on va jouer sur la taille des filtres (5,5) a la place de (3,3)  #on a une couche\n",
        "# create model\n",
        "modelCNN10 = Sequential()\n",
        "modelCNN10.add(Conv2D(32, (5, 5), input_shape=(28,28,1), padding='same',activation='relu'))\n",
        "modelCNN10.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN10.add(Dropout(0.2))\n",
        "modelCNN10.add(Flatten())\n",
        "modelCNN10.add(Dense(128, activation='relu'))\n",
        "modelCNN10.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN10.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN10.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score11 = modelCNN10.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score11[0])\n",
        "print('Test accuracy:', score11[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpu_oE9ifCwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8K3lmHpYifC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN11 Le Net 5\n",
        "modelCNN11 = keras.Sequential()\n",
        "\n",
        "modelCNN11.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same',input_shape=(28,28,1)))\n",
        "modelCNN11.add(AveragePooling2D())\n",
        "\n",
        "modelCNN11.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "modelCNN11.add(AveragePooling2D())\n",
        "\n",
        "modelCNN11.add(Flatten())\n",
        "\n",
        "modelCNN11.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "modelCNN11.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "modelCNN11.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "# Compile model\n",
        "modelCNN11.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN11.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score12 = modelCNN11.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score12[0])\n",
        "print('Test accuracy:', score12[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTzMkU3AfD9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlegCnaZYjgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN12 \n",
        "modelCNN12 = Sequential()\n",
        "modelCNN12.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last', input_shape=(28,28,1)))\n",
        "modelCNN12.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "\n",
        "modelCNN12.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last'))\n",
        "modelCNN12.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN12.add(Dropout(0.25))\n",
        "\n",
        "modelCNN12.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last'))\n",
        "modelCNN12.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "modelCNN12.add(Dropout(0.25))\n",
        "    \n",
        "    \n",
        "modelCNN12.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
        "                 data_format='channels_last'))\n",
        "modelCNN12.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN12.add(Dropout(0.25))\n",
        "\n",
        "modelCNN12.add(Flatten())\n",
        "modelCNN12.add(Dense(512, activation='relu'))\n",
        "modelCNN12.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN12.add(Dropout(0.5))\n",
        "modelCNN12.add(Dense(128, activation='relu'))\n",
        "modelCNN12.add(tf.compat.v2.keras.layers.BatchNormalization())\n",
        "modelCNN12.add(Dropout(0.5))\n",
        "modelCNN12.add(Dense(10, activation='softmax'))\n",
        "# Compile model\n",
        "modelCNN12.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit du model\n",
        "modelCNN12.fit(train_image, train_labels, validation_data=(test_image, test_labels), epochs=10, batch_size=200)\n",
        "#score\n",
        "score13 = modelCNN12.evaluate(test_image, test_labels, verbose=1)\n",
        "print('Test loss:', score13[0])\n",
        "print('Test accuracy:', score13[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKIkQUUifFoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels), num_classes = get_and_prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGPji9QRXFD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN13\n",
        "modelCNN13 = Sequential()\n",
        "\n",
        "modelCNN13 .add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1) ))\n",
        "\n",
        "# No Pooling Layer and Dropout layer for first Convolutional layer 'conv1'\n",
        "modelCNN13 .add(Conv2D(64, (3,3), activation='relu'))\n",
        "modelCNN13 .add(MaxPooling2D((2,2)))\n",
        "modelCNN13 .add(Dropout(0.5))\n",
        "modelCNN13 .add(Conv2D(128, (3,3), activation='relu'))\n",
        "modelCNN13 .add(MaxPooling2D((2,2)))\n",
        "modelCNN13 .add(Dropout(0.5))\n",
        "modelCNN13 .add(Flatten())\n",
        "modelCNN13 .add(Dense(128, activation='relu'))\n",
        "modelCNN13 .add(Dense(10, 'softmax'))\n",
        "modelCNN13 .compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "modelCNN13 .fit(train_image, train_labels, epochs=10, batch_size=512, shuffle=True, validation_split=0.1)\n",
        "test_loss, test_accuracy = modelCNN13 .evaluate(test_image, test_labels)\n",
        "print(test_loss)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC5Gzu2qfHC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels)= get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH2jp6FKSxAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model knn\n",
        "nsamples, nx, ny, nz = train_image.shape\n",
        "train_image= train_image.reshape((nsamples,nx*ny*nz))\n",
        "nsamples, nx, ny, nz = test_image.shape\n",
        "test_image= test_image.reshape((nsamples,nx*ny*nz))\n",
        "modelKNN = KNeighborsClassifier()\n",
        "tO= time.time()\n",
        "modelKNN.fit(train_image, train_labels)\n",
        "t1= time.time()\n",
        "y_pred_knn = modelKNN.predict(test_image)\n",
        "t2= time.time()\n",
        "acc_knn = accuracy_score(test_labels, y_pred_knn)\n",
        "print(\"nearest neighbors accuracy: \",acc_knn)\n",
        "print(\"duree d'apprentissage du model\", t1- t0)\n",
        "print(\"duree de prediction du model\",t2- t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZXTRwFNfz6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels) = get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQRl6RnSxwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "modelRF = RandomForestClassifier()\n",
        "nsamples, nx, ny, nz = train_image.shape\n",
        "train_image= train_image.reshape((nsamples,nx*ny*nz))\n",
        "nsamples, nx, ny, nz = test_image.shape\n",
        "test_image= test_image.reshape((nsamples,nx*ny*nz))\n",
        "tO= time.time()\n",
        "\n",
        "modelRF.fit(train_image, train_labels)\n",
        "t1= time.time()\n",
        "y_pred_rf = modelRF.predict(test_image)\n",
        "t2= time.time()\n",
        "acc_rf = accuracy_score(test_labels, y_pred_rf)\n",
        "print (\"random forest accuracy: \",acc_rf)\n",
        "print(\"duree d'apprentissage du model\", t1- tO)\n",
        "print(\"duree de prediction du model\",t2- t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eks9DR5lf5UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels) = get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgG8t6iwS5ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Stochastic Gradient Descent\n",
        "nsamples, nx, ny, nz = train_image.shape\n",
        "train_image= train_image.reshape((nsamples,nx*ny*nz))\n",
        "nsamples, nx, ny, nz = test_image.shape\n",
        "test_image= test_image.reshape((nsamples,nx*ny*nz))\n",
        "modelSGD = SGDClassifier()\n",
        "tO= time.time()\n",
        "modelSGD.fit(train_image, train_labels)\n",
        "t1= time.time()\n",
        "y_pred_sgd = modelSGD.predict(test_image)\n",
        "t2= time.time()\n",
        "acc_sgd = accuracy_score(test_labels, y_pred_sgd)\n",
        "print (\"stochastic gradient descent accuracy: \", acc_sgd)\n",
        "print(\"duree d'apprentissage du model\", t1- tO)\n",
        "print(\"duree de prediction du model\",t2- t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqCp8xOhf6_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels)= get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfd0pKafS9zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#methode SVM\n",
        "nsamples, nx, ny, nz = train_image.shape\n",
        "train_image= train_image.reshape((nsamples,nx*ny*nz))\n",
        "nsamples, nx, ny, nz = test_image.shape\n",
        "test_image= test_image.reshape((nsamples,nx*ny*nz))\n",
        "modelSVC = LinearSVC()\n",
        "tO= time.time()\n",
        "modelSVC.fit(train_image, train_labels)\n",
        "t1= time.time()\n",
        "y_pred_svm = modelSVC.predict(test_image)\n",
        "t2= time.time()\n",
        "acc_svm = accuracy_score(test_labels, y_pred_svm)\n",
        "print(\"Linear SVM accuracy: \",acc_svm)\n",
        "print(\"duree d'apprentissage du model\", t1- tO)\n",
        "print(\"duree de prediction du model\",t2- t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKjMIBGvf-kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels)= get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnfPONfwS-ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#methode Regression Logistique \n",
        "nsamples, nx, ny, nz = train_image.shape\n",
        "train_image= train_image.reshape((nsamples,nx*ny*nz))\n",
        "nsamples, nx, ny, nz = test_image.shape\n",
        "test_image= test_image.reshape((nsamples,nx*ny*nz))\n",
        "modelLOG= LogisticRegression(solver = 'lbfgs')\n",
        "tO= time.time()\n",
        "modelLOG.fit(train_image, train_labels)\n",
        "t1= time.time()\n",
        "predictions = modelLOG.predict(test_image)\n",
        "t2= time.time()\n",
        "acc_log = modelLOG.score(test_image, test_labels)\n",
        "print(\"model regression Logistic score\", acc_log)\n",
        "print(\"duree d'apprentissage du model\", t1- tO)\n",
        "print(\"duree de prediction du model\",t2- t1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R6kPFDxgVWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_image, train_labels), (test_image, test_labels)= get_and_prepare_data2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "304v8PJdTBtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#methode Arbre de decision \n",
        "nsamples, nx, ny, nz = train_image.shape\n",
        "train_image= train_image.reshape((nsamples,nx*ny*nz))\n",
        "nsamples, nx, ny, nz = test_image.shape\n",
        "test_image= test_image.reshape((nsamples,nx*ny*nz))\n",
        "modelDT = tree.DecisionTreeClassifier()\n",
        "tO= time.time()\n",
        "modelDT= modelDT.fit(train_image, train_labels)\n",
        "t1= time.time()\n",
        "y_pred = modelDT.predict(test_image)\n",
        "t2= time.time()\n",
        "print(\"model decision tree score\",metrics.accuracy_score(test_labels, y_pred))\n",
        "print(\"duree d'apprentissage du model\", t1- t0)\n",
        "print(\"duree de prediction du model\",t2- t1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}